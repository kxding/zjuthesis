% use `texdoc biblatex` to get help
@www{zjuthesisrules,
    title = {浙江大学本科生毕业论文（设计）编写规则},
    author = {浙江大学本科生院},
    year = {2018},
    url = {http://bksy.zju.edu.cn/attachments/2018-01/01-1517384518-1149149.pdf},
}
@www{tikz,
    title = {tikz宏包},
    author = {Till Tantau},
    year = {2018},
    url = {https://sourceforge.net/projects/pgf/},
}
@www{zjuthesis,
    title = {浙江大学毕业设计/论文模板},
    author = {王子轩},
    year = {2019},
    url = {https://github.com/TheNetAdmin/zjuthesis},
}
@www{zjugradthesisrules,
    title = {浙江大学研究生学位论文编写规则},
    author = {浙江大学研究生院},
    year = {2008},
    url = {http://grs.zju.edu.cn/redir.php?catalog_id=10038&object_id=12877},
}
@article{blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}
@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}
@article{hong2022cogvideo,
  title={Cogvideo: Large-scale pretraining for text-to-video generation via transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  journal={arXiv preprint arXiv:2205.15868},
  year={2022}
}
@article{yang2024cogvideox,
  title={Cogvideox: Text-to-video diffusion models with an expert transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}
@article{li2023videogen,
  title={Videogen: A reference-guided latent diffusion approach for high definition text-to-video generation},
  author={Li, Xin and Chu, Wenqing and Wu, Ye and Yuan, Weihang and Liu, Fanglong and Zhang, Qi and Li, Fu and Feng, Haocheng and Ding, Errui and Wang, Jingdong},
  journal={arXiv preprint arXiv:2309.00398},
  year={2023}
}
@article{zhang2023controlvideo,
  title={Controlvideo: Training-free controllable text-to-video generation},
  author={Zhang, Yabo and Wei, Yuxiang and Jiang, Dongsheng and Zhang, Xiaopeng and Zuo, Wangmeng and Tian, Qi},
  journal={arXiv preprint arXiv:2305.13077},
  year={2023}
}
@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}
@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}
@inproceedings{blattmann2023align,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={22563--22575},
  year={2023}
}
@inproceedings{ruiz2023dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={22500--22510},
  year={2023}
}
@article{huang2024consistentid,
  title={Consistentid: Portrait generation with multimodal fine-grained identity preserving},
  author={Huang, Jiehui and Dong, Xiao and Song, Wenhui and Chong, Zheng and Tang, Zhenchao and Zhou, Jun and Cheng, Yuhao and Chen, Long and Li, Hanhui and Yan, Yiqiang and others},
  journal={arXiv preprint arXiv:2404.16771},
  year={2024}
}
@inproceedings{zhao2024motiondirector,
  title={Motiondirector: Motion customization of text-to-video diffusion models},
  author={Zhao, Rui and Gu, Yuchao and Wu, Jay Zhangjie and Zhang, David Junhao and Liu, Jia-Wei and Wu, Weijia and Keppo, Jussi and Shou, Mike Zheng},
  booktitle={European Conference on Computer Vision},
  pages={273--290},
  year={2024},
  organization={Springer}
}
@article{ye2023ip,
  title={Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models},
  author={Ye, Hu and Zhang, Jun and Liu, Sibo and Han, Xiao and Yang, Wei},
  journal={arXiv preprint arXiv:2308.06721},
  year={2023}
}
@inproceedings{yuan2023physdiff,
  title={Physdiff: Physics-guided human motion diffusion model},
  author={Yuan, Ye and Song, Jiaming and Iqbal, Umar and Vahdat, Arash and Kautz, Jan},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={16010--16021},
  year={2023}
}
@article{kodaira2023streamdiffusion,
  title={Streamdiffusion: A pipeline-level solution for real-time interactive generation},
  author={Kodaira, Akio and Xu, Chenfeng and Hazama, Toshiki and Yoshimoto, Takanori and Ohno, Kohei and Mitsuhori, Shogo and Sugano, Soichi and Cho, Hanying and Liu, Zhijian and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2312.12491},
  year={2023}
}
@article{zhang2025magic,
  title={Magic Mirror: ID-Preserved Video Generation in Video Diffusion Transformers},
  author={Zhang, Yuechen and Liu, Yaoyang and Xia, Bin and Peng, Bohao and Yan, Zexin and Lo, Eric and Jia, Jiaya},
  journal={arXiv preprint arXiv:2501.03931},
  year={2025}
}
@article{huang2025conceptmaster,
  title={ConceptMaster: Multi-Concept Video Customization on Diffusion Transformer Models Without Test-Time Tuning},
  author={Huang, Yuzhou and Yuan, Ziyang and Liu, Quande and Wang, Qiulin and Wang, Xintao and Zhang, Ruimao and Wan, Pengfei and Zhang, Di and Gai, Kun},
  journal={arXiv preprint arXiv:2501.04698},
  year={2025}
}
@article{huang2024style,
  title={Style-a-video: Agile diffusion for arbitrary text-based video style transfer},
  author={Huang, Nisha and Zhang, Yuxin and Dong, Weiming},
  journal={IEEE Signal Processing Letters},
  year={2024},
  publisher={IEEE}
}
@article{zhou2023characterglm,
  title={Characterglm: Customizing chinese conversational ai characters with large language models},
  author={Zhou, Jinfeng and Chen, Zhuang and Wan, Dazhen and Wen, Bosi and Song, Yi and Yu, Jifan and Huang, Yongkang and Peng, Libiao and Yang, Jiaming and Xiao, Xiyao and others},
  journal={arXiv preprint arXiv:2311.16832},
  year={2023}
}
@article{liu2024sora,
  title={Sora: A review on background, technology, limitations, and opportunities of large vision models},
  author={Liu, Yixin and Zhang, Kai and Li, Yuan and Yan, Zhiling and Gao, Chujie and Chen, Ruoxi and Yuan, Zhengqing and Huang, Yue and Sun, Hanchi and Gao, Jianfeng and others},
  journal={arXiv preprint arXiv:2402.17177},
  year={2024}
}
@article{sun2024hunyuan,
  title={Hunyuan-large: An open-source moe model with 52 billion activated parameters by tencent},
  author={Sun, Xingwu and Chen, Yanfeng and Huang, Yiqing and Xie, Ruobing and Zhu, Jiaqi and Zhang, Kai and Li, Shuaipeng and Yang, Zhen and Han, Jonny and Shu, Xiaobo and others},
  journal={arXiv preprint arXiv:2411.02265},
  year={2024}
}
@article{ma2024magic,
  title={Magic-me: Identity-specific video customized diffusion},
  author={Ma, Ze and Zhou, Daquan and Yeh, Chun-Hsiao and Wang, Xue-She and Li, Xiuyu and Yang, Huanrui and Dong, Zhen and Keutzer, Kurt and Feng, Jiashi},
  journal={arXiv preprint arXiv:2402.09368},
  year={2024}
}
@article{hu2022lora,
  title={Lora: Low-rank adaptation of large language models.},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  journal={ICLR},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}
@inproceedings{wu2023tune,
  title={Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation},
  author={Wu, Jay Zhangjie and Ge, Yixiao and Wang, Xintao and Lei, Stan Weixian and Gu, Yuchao and Shi, Yufei and Hsu, Wynne and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7623--7633},
  year={2023}
}
@inproceedings{xing2024dynamicrafter,
  title={Dynamicrafter: Animating open-domain images with video diffusion priors},
  author={Xing, Jinbo and Xia, Menghan and Zhang, Yong and Chen, Haoxin and Yu, Wangbo and Liu, Hanyuan and Liu, Gongye and Wang, Xintao and Shan, Ying and Wong, Tien-Tsin},
  booktitle={European Conference on Computer Vision},
  pages={399--417},
  year={2024},
  organization={Springer}
}
@article{sun2024outfitanyone,
  title={Outfitanyone: Ultra-high quality virtual try-on for any clothing and any person},
  author={Sun, Ke and Cao, Jian and Wang, Qi and Tian, Linrui and Zhang, Xindi and Zhuo, Lian and Zhang, Bang and Bo, Liefeng and Zhou, Wenbo and Zhang, Weiming and others},
  journal={arXiv preprint arXiv:2407.16224},
  year={2024}
}
@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = ICCV,
pages = {234--778},
year = 2005
}


@misc{blackforestlabs_flux,
  author       = {Black Forest Labs},
  title        = {FLUX: Official Inference Repository for FLUX.1 Models},
  year         = 2024,
  url          = {https://github.com/black-forest-labs/flux},
  note         = {Accessed: 2024-11-12}
}

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@article{chen2023pixart,
  title={PixArt-$\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis},
  author={Chen, Junsong and Yu, Jincheng and Ge, Chongjian and Yao, Lewei and Xie, Enze and Wu, Yue and Wang, Zhongdao and Kwok, James and Luo, Ping and Lu, Huchuan and Li, Zhenguo},
  journal={arXiv preprint arXiv:2310.00426},
  year={2023}
}

@misc{rombach2021highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{su2024roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

@article{lipman2022flow,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  journal={arXiv preprint arXiv:2210.02747},
  year={2022}
}

@inproceedings{ruan2023mm,
  title={Mm-diffusion: Learning multi-modal diffusion models for joint audio and video generation},
  author={Ruan, Ludan and Ma, Yiyang and Yang, Huan and He, Huiguo and Liu, Bei and Fu, Jianlong and Yuan, Nicholas Jing and Jin, Qin and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10219--10228},
  year={2023}
}

@inproceedings{esser2024scaling,
  title={Scaling rectified flow transformers for high-resolution image synthesis},
  author={Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others},
  booktitle={Forty-first international conference on machine learning},
  year={2024}
}

@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3836--3847},
  year={2023}
}

@inproceedings{mou2024t2i,
  title={T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models},
  author={Mou, Chong and Wang, Xintao and Xie, Liangbin and Wu, Yanze and Zhang, Jian and Qi, Zhongang and Shan, Ying},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={5},
  pages={4296--4304},
  year={2024}
}
@inproceedings{kumari2023multi,
  title={Multi-concept customization of text-to-image diffusion},
  author={Kumari, Nupur and Zhang, Bingliang and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1931--1941},
  year={2023}
}

@article{li2024blip,
  title={Blip-diffusion: Pre-trained subject representation for controllable text-to-image generation and editing},
  author={Li, Dongxu and Li, Junnan and Hoi, Steven},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{li2024photomaker,
  title={Photomaker: Customizing realistic human photos via stacked id embedding},
  author={Li, Zhen and Cao, Mingdeng and Wang, Xintao and Qi, Zhongang and Cheng, Ming-Ming and Shan, Ying},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8640--8650},
  year={2024}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{mishchenko2024prodigy,
    title={Prodigy: An Expeditiously Adaptive Parameter-Free Learner},
    author={Mishchenko, Konstantin and Defazio, Aaron},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
    url={https://openreview.net/forum?id=JJpOssn0uP}
}

@inproceedings{yang2024depth,
  title={Depth anything: Unleashing the power of large-scale unlabeled data},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10371--10381},
  year={2024}
}

@misc{jackyhate2024t2i,
  title = {Text-to-Image-2M Dataset},
  author = {Jacky Hate},
  year = {2024},
  howpublished = {\url{https://huggingface.co/datasets/jackyhate/text-to-image-2M}},
}


@misc{fluxipadapter2024,
  title = {FLUX-IP-Adapter},
  author = {XLabs-AI},
  year = {2024},
  howpublished = {\url{https://huggingface.co/XLabs-AI/flux-ip-adapter}},
}

@misc{flux1controlnet2024,
  title = {FLUX.1-dev-ControlNet-Union-Pro},
  author = {Shakker Labs},
  year = {2024},
  howpublished = {\url{https://huggingface.co/Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro}},
}

@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{yang2022maniqa,
  title={MANIQA: Multi-dimension Attention Network for No-Reference Image Quality Assessment},
  author={Yang, Sidi and Wu, Tianhe and Shi, Shuwei and Lao, Shanshan and Gong, Yuan and Cao, Mingdeng and Wang, Jiahao and Yang, Yujiu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1191--1200},
  year={2022}
}

@inproceedings{ke2021musiq,
  title={Musiq: Multi-scale image quality transformer},
  author={Ke, Junjie and Wang, Qifei and Wang, Yilin and Milanfar, Peyman and Yang, Feng},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={5148--5157},
  year={2021}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{wang2004image,
  title={Image quality assessment: from error visibility to structural similarity},
  author={Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
  journal={IEEE transactions on image processing},
  volume={13},
  number={4},
  pages={600--612},
  year={2004},
  publisher={IEEE}
}

@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{zhao2024uni,
  title={Uni-controlnet: All-in-one control to text-to-image diffusion models},
  author={Zhao, Shihao and Chen, Dongdong and Chen, Yen-Chun and Bao, Jianmin and Hao, Shaozhe and Yuan, Lu and Wong, Kwan-Yee K},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{podell2023sdxl,
  title={Sdxl: Improving latent diffusion models for high-resolution image synthesis},
  author={Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and M{\"u}ller, Jonas and Penna, Joe and Rombach, Robin},
  journal={arXiv preprint arXiv:2307.01952},
  year={2023}
}


@article{tian2024visual,
  title={Visual autoregressive modeling: Scalable image generation via next-scale prediction},
  author={Tian, Keyu and Jiang, Yi and Yuan, Zehuan and Peng, Bingyue and Wang, Liwei},
  journal={arXiv preprint arXiv:2404.02905},
  year={2024}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9650--9660},
  year={2021}
}

@inproceedings{devalal2018lora,
  title={LoRa technology-an overview},
  author={Devalal, Shilpa and Karthikeyan, A},
  booktitle={2018 second international conference on electronics, communication and aerospace technology (ICECA)},
  pages={284--290},
  year={2018},
  organization={IEEE}
}


@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@inproceedings{zhang2024ssr,
  title={Ssr-encoder: Encoding selective subject representation for subject-driven generation},
  author={Zhang, Yuxuan and Song, Yiren and Liu, Jiaming and Wang, Rui and Yu, Jinpeng and Tang, Hao and Li, Huaxia and Tang, Xu and Hu, Yao and Pan, Han and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8069--8078},
  year={2024}
}

@inproceedings{ma2024subject,
  title={Subject-diffusion: Open domain personalized text-to-image generation without test-time fine-tuning},
  author={Ma, Jian and Liang, Junhao and Chen, Chen and Lu, Haonan},
  booktitle={ACM SIGGRAPH 2024 Conference Papers},
  pages={1--12},
  year={2024}
}

@article{zavadski2023controlnet,
  title={Controlnet-xs: Designing an efficient and effective architecture for controlling text-to-image diffusion models},
  author={Zavadski, Denis and Feiden, Johann-Friedrich and Rother, Carsten},
  journal={arXiv preprint arXiv:2312.06573},
  year={2023}
}

@article{peng2024controlnext,
  title={Controlnext: Powerful and efficient control for image and video generation},
  author={Peng, Bohao and Wang, Jian and Zhang, Yuechen and Li, Wenbo and Yang, Ming-Chang and Jia, Jiaya},
  journal={arXiv preprint arXiv:2408.06070},
  year={2024}
}

@inproceedings{li2025controlnet,
  title={ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback},
  author={Li, Ming and Yang, Taojiannan and Kuang, Huafeng and Wu, Jie and Wang, Zhaoning and Xiao, Xuefeng and Chen, Chen},
  booktitle={European Conference on Computer Vision},
  pages={129--147},
  year={2025},
  organization={Springer}
}

@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

@article{gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01618},
  year={2022}
}

@inproceedings{saharia2022palette,
  title={Palette: Image-to-image diffusion models},
  author={Saharia, Chitwan and Chan, William and Chang, Huiwen and Lee, Chris and Ho, Jonathan and Salimans, Tim and Fleet, David and Norouzi, Mohammad},
  booktitle={ACM SIGGRAPH 2022 conference proceedings},
  pages={1--10},
  year={2022}
}

@article{meng2021sdedit,
  title={Sdedit: Guided image synthesis and editing with stochastic differential equations},
  author={Meng, Chenlin and He, Yutong and Song, Yang and Song, Jiaming and Wu, Jiajun and Zhu, Jun-Yan and Ermon, Stefano},
  journal={arXiv preprint arXiv:2108.01073},
  year={2021}
}

@inproceedings{avrahami2022blended,
  title={Blended diffusion for text-driven editing of natural images},
  author={Avrahami, Omri and Lischinski, Dani and Fried, Ohad},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={18208--18218},
  year={2022}
}

@article{chen2024pixart,
  title={Pixart-$\{$$\backslash$delta$\}$: Fast and controllable image generation with latent consistency models},
  author={Chen, Junsong and Wu, Yue and Luo, Simian and Xie, Enze and Paul, Sayak and Luo, Ping and Zhao, Hang and Li, Zhenguo},
  journal={arXiv preprint arXiv:2401.05252},
  year={2024}
}

@article{qin2023unicontrol,
  title={Unicontrol: A unified diffusion model for controllable visual generation in the wild},
  author={Qin, Can and Zhang, Shu and Yu, Ning and Feng, Yihao and Yang, Xinyi and Zhou, Yingbo and Wang, Huan and Niebles, Juan Carlos and Xiong, Caiming and Savarese, Silvio and others},
  journal={arXiv preprint arXiv:2305.11147},
  year={2023}
}

@article{pan2020multi,
  title={Multi-modal attention for speech emotion recognition},
  author={Pan, Zexu and Luo, Zhaojie and Yang, Jichen and Li, Haizhou},
  journal={arXiv preprint arXiv:2009.04107},
  year={2020}
}

@misc{chang2025xdynaexpressivedynamichuman,
      title={X-Dyna: Expressive Dynamic Human Image Animation}, 
      author={Di Chang and Hongyi Xu and You Xie and Yipeng Gao and Zhengfei Kuang and Shengqu Cai and Chenxu Zhang and Guoxian Song and Chao Wang and Yichun Shi and Zeyuan Chen and Shijie Zhou and Linjie Luo and Gordon Wetzstein and Mohammad Soleymani},
      year={2025},
      eprint={2501.10021},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2501.10021}, 
}

@article{tan2024ominicontrol,
  title={Ominicontrol: Minimal and universal control for diffusion transformer},
  author={Tan, Zhenxiong and Liu, Songhua and Yang, Xingyi and Xue, Qiaochu and Wang, Xinchao},
  journal={arXiv preprint arXiv:2411.15098},
  volume={3},
  year={2024}
}


@inproceedings{wei2023elite,
  title={Elite: Encoding visual concepts into textual embeddings for customized text-to-image generation},
  author={Wei, Yuxiang and Zhang, Yabo and Ji, Zhilong and Bai, Jinfeng and Zhang, Lei and Zuo, Wangmeng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15943--15953},
  year={2023}
}

@inproceedings{shi2024instantbooth,
  title={Instantbooth: Personalized text-to-image generation without test-time finetuning},
  author={Shi, Jing and Xiong, Wei and Lin, Zhe and Jung, Hyun Joon},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8543--8552},
  year={2024}
}


@article{xiao2024fastcomposer,
  title={Fastcomposer: Tuning-free multi-subject image generation with localized attention},
  author={Xiao, Guangxuan and Yin, Tianwei and Freeman, William T and Durand, Fr{\'e}do and Han, Song},
  journal={International Journal of Computer Vision},
  pages={1--20},
  year={2024},
  publisher={Springer}
}

@misc{heusel2018ganstrainedtimescaleupdate,
      title={GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium}, 
      author={Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Sepp Hochreiter},
      year={2018},
      eprint={1706.08500},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1706.08500}, 
}

@online{Wikipedia2024psnr,
  author    = {Wikipedia contributors},
  title     = {Peak signal-to-noise ratio},
  year      = {2024},
  url       = {https://en.wikipedia.org/w/index.php?title=Peak_signal-to-noise_ratio&oldid=1210897995},
  note      = {Accessed: 2024-03-04}
}

@misc{wang2022exploringclipassessinglook,
      title={Exploring CLIP for Assessing the Look and Feel of Images}, 
      author={Jianyi Wang and Kelvin C. K. Chan and Chen Change Loy},
      year={2022},
      eprint={2207.12396},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2207.12396}, 
}

@article{pan2023kosmos,
  title={Kosmos-g: Generating images in context with multimodal large language models},
  author={Pan, Xichen and Dong, Li and Huang, Shaohan and Peng, Zhiliang and Chen, Wenhu and Wei, Furu},
  journal={arXiv preprint arXiv:2310.02992},
  year={2023}
}

@misc{li2025controlarcontrollableimagegeneration,
      title={ControlAR: Controllable Image Generation with Autoregressive Models}, 
      author={Zongming Li and Tianheng Cheng and Shoufa Chen and Peize Sun and Haocheng Shen and Longjin Ran and Xiaoxin Chen and Wenyu Liu and Xinggang Wang},
      year={2025},
      eprint={2410.02705},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.02705}, 
}

@misc{he2024dynamiccontroladaptiveconditionselection,
      title={DynamicControl: Adaptive Condition Selection for Improved Text-to-Image Generation}, 
      author={Qingdong He and Jinlong Peng and Pengcheng Xu and Boyuan Jiang and Xiaobin Hu and Donghao Luo and Yong Liu and Yabiao Wang and Chengjie Wang and Xiangtai Li and Jiangning Zhang},
      year={2024},
      eprint={2412.03255},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.03255}, 
}

@misc{sun2024anycontrolcreateartworkversatile,
      title={AnyControl: Create Your Artwork with Versatile Control on Text-to-Image Generation}, 
      author={Yanan Sun and Yanchen Liu and Yinhao Tang and Wenjie Pei and Kai Chen},
      year={2024},
      eprint={2406.18958},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.18958}, 
}

@article{bar2023multidiffusion,
  title={Multidiffusion: Fusing diffusion paths for controlled image generation},
  author={Bar-Tal, Omer and Yariv, Lior and Lipman, Yaron and Dekel, Tali},
  year={2023}
}

@misc{lin2024ctrlxcontrollingstructureappearance,
      title={Ctrl-X: Controlling Structure and Appearance for Text-To-Image Generation Without Guidance}, 
      author={Kuan Heng Lin and Sicheng Mo and Ben Klingher and Fangzhou Mu and Bolei Zhou},
      year={2024},
      eprint={2406.07540},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.07540}, 
}

@misc{hua2023dreamtunersingleimagesubjectdriven,
      title={DreamTuner: Single Image is Enough for Subject-Driven Generation}, 
      author={Miao Hua and Jiawei Liu and Fei Ding and Wei Liu and Jie Wu and Qian He},
      year={2023},
      eprint={2312.13691},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.13691}, 
}

@misc{he2025anystoryunifiedsinglemultiple,
      title={AnyStory: Towards Unified Single and Multiple Subject Personalization in Text-to-Image Generation}, 
      author={Junjie He and Yuxiang Tuo and Binghui Chen and Chongyang Zhong and Yifeng Geng and Liefeng Bo},
      year={2025},
      eprint={2501.09503},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2501.09503}, 
}

@misc{ma2024characteradapterpromptguidedregioncontrol,
      title={Character-Adapter: Prompt-Guided Region Control for High-Fidelity Character Customization}, 
      author={Yuhang Ma and Wenting Xu and Jiji Tang and Qinfeng Jin and Rongsheng Zhang and Zeng Zhao and Changjie Fan and Zhipeng Hu},
      year={2024},
      eprint={2406.16537},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.16537}, 
}

@article{huang2024context,
  title={In-context lora for diffusion transformers},
  author={Huang, Lianghua and Wang, Wei and Wu, Zhi-Fan and Shi, Yupeng and Dou, Huanzhang and Liang, Chen and Feng, Yutong and Liu, Yu and Zhou, Jingren},
  journal={arXiv preprint arXiv:2410.23775},
  year={2024}
}

@article{huang2024group,
  title={Group diffusion transformers are unsupervised multitask learners},
  author={Huang, Lianghua and Wang, Wei and Wu, Zhi-Fan and Dou, Huanzhang and Shi, Yupeng and Feng, Yutong and Liang, Chen and Liu, Yu and Zhou, Jingren},
  year={2024}
}

@article{mao2025ace++,
  title={Ace++: Instruction-based image creation and editing via context-aware content filling},
  author={Mao, Chaojie and Zhang, Jingfeng and Pan, Yulin and Jiang, Zeyinzi and Han, Zhen and Liu, Yu and Zhou, Jingren},
  journal={arXiv preprint arXiv:2501.02487},
  year={2025}
}

@article{han2024ace,
  title={ACE: All-round Creator and Editor Following Instructions via Diffusion Transformer},
  author={Han, Zhen and Jiang, Zeyinzi and Pan, Yulin and Zhang, Jingfeng and Mao, Chaojie and Xie, Chenwei and Liu, Yu and Zhou, Jingren},
  journal={arXiv preprint arXiv:2410.00086},
  year={2024}
}

@article{cai2024diffusion,
  title={Diffusion self-distillation for zero-shot customized image generation},
  author={Cai, Shengqu and Chan, Eric and Zhang, Yunzhi and Guibas, Leonidas and Wu, Jiajun and Wetzstein, Gordon},
  journal={arXiv preprint arXiv:2411.18616},
  year={2024}
}

@article{choi2024style,
  title={Style-Friendly SNR Sampler for Style-Driven Generation},
  author={Choi, Jooyoung and Shin, Chaehun and Oh, Yeongtak and Kim, Heeseung and Yoon, Sungroh},
  journal={arXiv preprint arXiv:2411.14793},
  year={2024}
}

@article{li2023blip,
  title={Blip-diffusion: Pre-trained subject representation for controllable text-to-image generation and editing},
  author={Li, Dongxu and Li, Junnan and Hoi, Steven},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={30146--30166},
  year={2023}
}

@article{rout2024semantic,
  title={Semantic image inversion and editing using rectified stochastic differential equations},
  author={Rout, Litu and Chen, Yujia and Ruiz, Nataniel and Caramanis, Constantine and Shakkottai, Sanjay and Chu, Wen-Sheng},
  journal={arXiv preprint arXiv:2410.10792},
  year={2024}
}

@article{wang2024instantid,
  title={Instantid: Zero-shot identity-preserving generation in seconds},
  author={Wang, Qixun and Bai, Xu and Wang, Haofan and Qin, Zekui and Chen, Anthony and Li, Huaxia and Tang, Xu and Hu, Yao},
  journal={arXiv preprint arXiv:2401.07519},
  year={2024}
}
@inproceedings{lazos2005rope,
  title={ROPE: Robust position estimation in wireless sensor networks},
  author={Lazos, Loukas and Poovendran, Radha and Capkun, Srdjan},
  booktitle={IPSN 2005. Fourth International Symposium on Information Processing in Sensor Networks, 2005.},
  pages={324--331},
  year={2005},
  organization={IEEE}
}
@article{chen2025multi,
  title={Multi-subject Open-set Personalization in Video Generation},
  author={Chen, Tsai-Shien and Siarohin, Aliaksandr and Menapace, Willi and Fang, Yuwei and Lee, Kwot Sin and Skorokhodov, Ivan and Aberman, Kfir and Zhu, Jun-Yan and Yang, Ming-Hsuan and Tulyakov, Sergey},
  journal={arXiv preprint arXiv:2501.06187},
  year={2025}
}
@inproceedings{wei2024dreamvideo,
  title={Dreamvideo: Composing your dream videos with customized subject and motion},
  author={Wei, Yujie and Zhang, Shiwei and Qing, Zhiwu and Yuan, Hangjie and Liu, Zhiheng and Liu, Yu and Zhang, Yingya and Zhou, Jingren and Shan, Hongming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6537--6549},
  year={2024}
}
@article{chen2023videodreamer,
  title={Videodreamer: Customized multi-subject text-to-video generation with disen-mix finetuning},
  author={Chen, Hong and Wang, Xin and Zeng, Guanning and Zhang, Yipeng and Zhou, Yuwei and Han, Feilin and Zhu, Wenwu},
  journal={arXiv preprint arXiv:2311.00990},
  year={2023}
}